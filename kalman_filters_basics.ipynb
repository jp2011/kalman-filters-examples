{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfhxUq79+xhpcOci0joQZe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jp2011/kalman-filters-examples/blob/main/kalman_filters_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Kalman Filter\n",
        "\n",
        "This is a detailed derivation of the filtering updates for the Kalman filter. The details follow closely the **Bayesian Filtering and Smoothing** book by *Simo Särkkä*.\n",
        "\n",
        "\n",
        "Note that all letters in the text refer to vectors or matrices rather than scalars, hence no boldface in the notation below.\n"
      ],
      "metadata": {
        "id": "tSN2XjXuzYm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminaries\n",
        "\n",
        "Before we proceed, we go through the derivation of some crucial properties of matrices and Gaussian random variables.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Inversion of a partitioned matrix\n",
        "\n",
        "Let $K$ be a invertible matrix partitioned as \n",
        "\\begin{equation}\n",
        "K = \\begin{pmatrix}\n",
        "    A & B\\\\\n",
        "    C & D\n",
        "    \\end{pmatrix}.\n",
        "\\end{equation}\n",
        "Its invers is the given by\n",
        "\\begin{equation}\n",
        "    \\begin{pmatrix}\n",
        "    A & B\\\\\n",
        "    C & D\n",
        "    \\end{pmatrix}^{-1}\n",
        "    = \n",
        "    \\begin{pmatrix}\n",
        "    M         & - M B D^{-1}\\\\\n",
        "    -D^{-1}CM & D^{-1} + D^{-1} C M B D^{-1}\n",
        "    \\end{pmatrix},\n",
        "\\end{equation}\n",
        "where $M = (A - BD^{-1}C)^{-1}$.\n",
        "\n",
        "### Joint distribution of a conditioned Gaussian on another Gaussian.\n",
        "\n",
        "To derive the Kalman filter, we require several properties of Gaussian random variables.\n",
        "\n",
        "Let $x$ and $y$ be random variables with Gaussian distributions:\n",
        "\\begin{align} \n",
        "x        & \\sim \\mathcal{N}(m, P), \\\\\n",
        "y \\mid x & \\sim \\mathcal{N}(Hx + u, R).\n",
        "\\end{align}\n",
        "The joint distribution of $x$ and $y$ is given as\n",
        "\\begin{equation}\n",
        "\\left(\\begin{array}{l}\n",
        "x \\\\\n",
        "y\n",
        "\\end{array}\\right) \\sim \\mathcal{N}\\left(\\left(\\begin{array}{c}\n",
        "m \\\\\n",
        "H m+u\n",
        "\\end{array}\\right),\\left(\\begin{array}{cc}\n",
        "P & P H^{\\top} \\\\\n",
        "H P & H P H^{\\top}+R\n",
        "\\end{array}\\right)\\right)\n",
        "\\end{equation}\n",
        "#### Proof\n",
        "Let $p(x,y)$ be the joint density.\n",
        "\\begin{align}\n",
        "\\log p(x, y) & = \\log p(y \\mid x) + \\log p(x) \\\\\n",
        "             & = -\\frac{1}{2}(y - Hx - u)^\\top R^{-1}(y - Hx - u)\n",
        "                 -\\frac{1}{2}(x - m)^\\top P^{-1} (x - m) + \\text{const}\n",
        "\\end{align}\n",
        "This is a quadratic function of $x$ and $y$ so the joint distribution must be Gaussian. Considering the second-order terms we obtain:\n",
        "\\begin{align}\n",
        "& - \\frac{1}{2} y^\\top R^{-1} y - \\frac{1}{2}x^{\\top}\\big(H^\\top R^{-1} H + P^{-1}\\big)x + \\frac{1}{2} y^\\top R^{-1} H x + \\frac{1}{2} x^\\top H^\\top R^{-1} y \\\\\n",
        "& = -\\frac{1}{2} \\begin{pmatrix} x \\\\ y \\end{pmatrix} ^ \\top \n",
        "     \\begin{pmatrix}\n",
        "         H^\\top R^{-1} H + P^{-1}      & - H^\\top R^{-1} \\\\\n",
        "         -R^{-1}H                      & R^{-1}\n",
        "     \\end{pmatrix}\n",
        "     \\begin{pmatrix} x \\\\ y \\end{pmatrix},\n",
        "\\end{align}\n",
        "from where the covariance matrix given by\n",
        "\\begin{equation}\n",
        "     \\begin{pmatrix}\n",
        "         H^\\top R^{-1} H + P^{-1}      & - H^\\top R^{-1} \\\\\n",
        "         -R^{-1}H                      & R^{-1}\n",
        "     \\end{pmatrix} ^ {-1}\n",
        "     = \\begin{pmatrix}\n",
        "           P        & P H^\\top \\\\\n",
        "           H^\\top P & R + H P H^\\top\n",
        "       \\end{pmatrix}.\n",
        "\\end{equation}\n",
        "\n"
      ],
      "metadata": {
        "id": "nFTafcAPeKHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Gaussian Model\n",
        "\n",
        "We have a time-evolving state process $x_k$ of which we observe a noisy version $y_k$ at time $k$. By assuming linear state transitions and Gaussian noise for both the process and the measurements the model is defined as follows:\n",
        "\\begin{align}\n",
        "x_k & = A_{k-1} x_{k-1} + q_{k-1}, \\\\\n",
        "y_K & = H_k x_k + r_k,\n",
        "\\end{align}\n",
        "where $A_{k}$, $H_k$, $Q_k$, and $R_k$ are given and \n",
        "\\begin{align}\n",
        "q_{k-1} & \\sim \\mathcal{N}(0, Q_{k-1}), \\\\\n",
        "r_{k}   & \\sim \\mathcal{N}(0, R_k),\n",
        "\\end{align}\n",
        "are the process and measurement noise, respectively."
      ],
      "metadata": {
        "id": "BuQByvyR6iY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering equations\n",
        "\n",
        "WIP, check back soon."
      ],
      "metadata": {
        "id": "EX_XtEsP9h1y"
      }
    }
  ]
}